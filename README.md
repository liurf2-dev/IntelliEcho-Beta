# IntelliEcho

## Project Description
### **EchoMind —— The Smart Assistant That Makes Meetings Easier**  

Can’t catch the key points in meetings? Struggling to keep up with the discussion? Don’t worry! **EchoMind** is an ultra-smart meeting assistant that transcribes speech in real-time, analyzes content, and even recommends thoughtful responses to help you stay on top of every conversation.  

---
### **Key Features**
🎤 **Real-Time Speech-to-Text**   
   Powered by multimodal large language models, EchoMind delivers millisecond-level transcription with multi-language support, making international meetings a breeze!  

👥 **Automatic Speaker Identification**  *(Coming Soon)*  
   Who said what? Smart speaker separation ensures clear and organized records, eliminating confusion.  

🧠 **AI-Powered Response Suggestions**   
   Backed by Qwen and a negotiation knowledge base, EchoMind quickly analyzes discussions and provides thoughtful, high-EQ response suggestions—no more awkward silences!  

🎯 **Customized for Different Scenarios**  *(Coming Soon)*  
   Tailored recommendations based on your role (manager, tech expert, etc.), ensuring smooth performance in any meeting context.  

🔒 **Privacy Protection + Offline Mode**   
   Fully offline processing ensures sensitive data stays secure—use it with peace of mind.  

📝 **Automated Meeting Notes**  *(Coming Soon)*  
   Export structured meeting notes with one click, including task assignments and follow-ups—saving you time and effort!  

---

### **Conclusion**  
**EchoMind** = Real-Time Transcription + Smart Analysis + Effective Communication 🚀  
Whether it’s a daily meeting or a brainstorming session, EchoMind has got you covered. Try it today and turn meetings into something you’ll actually enjoy! 😊

## Startup
1. Install the required packages by running `pip install -r requirements.txt`
2. Create .env file in the root directory and add the following:
```
QWEN_API_KEY = ***************************************
QWEN_BASE_URL = https://dashscope.aliyuncs.com/compatible-mode/v1

LANG_SMITH_API_KEY = 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
```
3. Run the app by running `python main.py`
4. Select the speaker device #, and the recording and analysis modules will start.